<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Journal Club</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

        <!-- Header -->
            <header id="header">
                <a href="index.html" class="title">JBCA Journal Club</a>
                <nav>
                    <ul>
                        <li><a href="index.html">Home</a></li>
                        <li><a href="workshop.html">Workshop</a></li>
                        <li><a href="hacknight.html">Hacknights</a></li>
                        <li><a href="ML_lunches.html">Lunch Talks</a></li>
			<li><a href="journalclub.html" class="active">Journal Club</a></li>
                    </ul>
                </nav>
            </header>

		<!-- Sidebar -->
			<section id="sidebar">
				<div class="inner">
					<nav>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="#intro">Overview</a></li>
							<li><a href="#9">2/2/2021</a></li>
							<li><a href="#8">12/1/2021</a></li>
							<li><a href="#7">1/12/2020</a></li>
							<li><a href="#6">3/11/2020</a></li>
							<li><a href="#5">8/9/2020</a></li>
							<li><a href="#4">7/7/2020</a></li>
							<li><a href="#3">2/6/2020</a></li>
							<li><a href="#2">5/5/2020</a></li>
							<li><a href="#1">7/4/2020</a></li>
						</ul>
					</nav>
				</div>
			</section>



		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Intro -->
					<section id="intro" class="wrapper style1 fullscreen fade-up">
						<div class="inner">
							<h1>Journal Club</h1>
							<p> We run monthly journal club (currently via Zoom) discussing relevant papers in machine learning with applications in astronomy. Here we provide links to the papers and any additional slides a speaker has made. 
								When it becomes safe to return to the office, we anticipate these sessions will be held at the SKA HQ at Jodrell Bank.</p>
						</div>
					</section>
		
				
	<!-- 2/2/2021 -->
        					<section id="9" class="wrapper style2 spotlights">
        						<section>
         							<a href="http://arxiv.org/abs/2102.01007" class="image" target="_blank"><img src="images/VAE_david.png" alt="" data-position="top center" /></a>
        							<div class="content">
        								<div class="inner">
        									<h2> Generating synthetic radio sources using variational auto encoders - David Bastien </h2>
        									<p> We present a novel machine learning technique that can be used for generating postage stamp images of synthetic Faranoff Riley Class 1 and Class 2 radio sources.
											Such a method will be useful in the simulations of future surveys like those being developed by the SKA as it can generate a large amount of unobserved sources. 
											We will introduce the basic concepts used in generative machine learning with a focus on variational auto-encoders (VAE) 
											which is our chosen methodology and will show how this can be applied to radio astronomy for the generation of FRIs and FRIIs.
											</p>
        									<td><a href="https://drive.google.com/file/d/1vWGOB3kakODToiZpkB_pH-l67DzOifT8/view" 
									       class="button primary small icon fa-download" target="_blank">Additional Slides</a></td>
										<td><a href="http://arxiv.org/abs/2102.01007" 
									       class="button primary small icon fa-download" target="_blank">Link to the paper</a></td>
        								</div>
        							</div>
        						</section>
                                </section>
        						<section>
                

              						<section>
								
				
	<!-- 12/1/2021 -->
        					<section id="8" class="wrapper style2 spotlights">
        						<section>
         							<a href="https://github.com/JBCA-MachineLearning/JBCA-MachineLearning.github.io/blob/master/journalclub_slides/11Jan2021_ML_Workflow.pdf" class="image" target="_blank"><img src="images/micah-ml-workflow.png" alt="" data-position="top center" /></a>
        							<div class="content">
        								<div class="inner">
        									<h2> Exploring a machine learning workflow - Micah Bowles </h2>
        									<p> Approaching a ML project can seem daunting, especially if you haven't seen a project through the full process before. 
											In this talk, I present an overview of what a workflow for a ML project might look like. Each step is explained along side an astronomy-centric example project to help ground each step in practical application, 
											which astronomers can relate to.
											</p>
        									<td><a href="https://github.com/JBCA-MachineLearning/JBCA-MachineLearning.github.io/blob/master/journalclub_slides/11Jan2021_ML_Workflow.pdf" 
									       class="button primary small icon fa-download" target="_blank">Additional Slides</a></td>
        								</div>
        							</div>
        						</section>
                                </section>
        						<section>
                

              						<section>			
	
	<!-- 1/12/2020 -->
        					<section id="7" class="wrapper style2 spotlights">
        						<section>
         							<a href="https://academic.oup.com/mnras/article/499/1/68/5906554" class="image" target="_blank"><img src="images/hongming_grg.png" alt="" data-position="top center" /></a>
        							<div class="content">
        								<div class="inner">
        									<h2> A Recap of hunting for giant radio galaxies: from visual inspection to machine learning - Hongming Tang </h2>
        									<p>In this talk I will recap the Giant Radio Galaxies searching pipelines people have adopted, 
											and introduce how people have changed their ways of finding these sources, 
											from doing visual inspection by experts,Â citizen scientists, to recent semi-automated algorithm development.
											I will also discuss what are the factors necessary when building a training dataset for training GRG-non GRG deep learing classifier.
											</p>
        									<td><a href="https://github.com/JBCA-MachineLearning/JBCA-MachineLearning.github.io/blob/master/journalclub_slides/HongmingTang_01122020_GRGHunting.pdf" 
									       class="button primary small icon fa-download" target="_blank">Additional Slides</a></td>
										<td><a href="https://academic.oup.com/mnras/article/499/1/68/5906554" 
									       class="button primary small icon fa-download" target="_blank">Link to the paper</a></td>
        								</div>
        							</div>
        						</section>
                                </section>
        						<section>
                

              						<section>
								
	<!-- 3/11/2020 -->
        					<section id="6" class="wrapper style2 spotlights">
        						<section>
         							<a href="https://arxiv.org/pdf/2009.12981.pdf" class="image" target="_blank"><img src="images/parametricUMAP-fig.png" alt="" data-position="top center" /></a>
        							<div class="content">
        								<div class="inner">
        									<h2> Neighbour-graphs for dimension reduction: Parametric UMAP - Alex Clarke </h2>
        									<p>I will introduce and discuss the advantages of neighbour-graph models for dimension reduction, 
											going over a recent paper that implements a parametric version of an algorithm called UMAP. 
											Their work allows a neighbour-graph loss function to be used with a deep neural network to learn a mapping 
											from a high to a low dimensional space. This means the UMAP loss function can be used in combination with 
											auto-encoder or classifier loss functions, for data generation or semi-supervised learning. 
											The UMAP loss function is particularly suited to regularising a deep neural network using sampled batches of data, 
											allowing real-time signal processing on big datasets (transients, pulsars, RFI). </p>
        									<td><a href="https://docs.google.com/presentation/d/1JkCGglnEqHh2ET5TGPtGms7g2YCpVmdIhjaCbjwI3p4/edit?usp=sharing" 
									       class="button primary small icon fa-download" target="_blank">Additional Slides</a></td>
										<td><a href="https://arxiv.org/pdf/2009.12981.pdf" 
									       class="button primary small icon fa-download" target="_blank">Link to the paper</a></td>
        								</div>
        							</div>
        						</section>
                                </section>
        						<section>
                

              						<section>
								
	<!-- 8/9/2020 -->
        					<section id="5" class="wrapper style2 spotlights">
        						<section>
         							<a href="https://arxiv.org/pdf/1804.02391.pdf" class="image" target="_blank"><img src="images/payattention-fig.png" alt="" data-position="top center" /></a>
        							<div class="content">
        								<div class="inner">
        									<h2>Learn to Pay Attention - Micah Bowles </h2>
        									<p>An end-to-end-trainable attention module for convolutional neural network (CNN) architectures 
											built for image classification. </p>
										<td><a href="https://arxiv.org/pdf/1804.02391.pdf" 
									       class="button primary small icon fa-download" target="_blank">Link to the paper</a></td>
        									
        								</div>
        							</div>
        						</section>
                                </section>
        						<section>
                

              						<section>
				
		
	<!-- 7/7/2020 -->
  					<section id="4" class="wrapper style2 spotlights">
  						<section>
  							<a href="https://arxiv.org/abs/1802.03609" class="image" target="_blank"><img src="images/stronglense.png" alt="" data-position="center center" /></a>
  							<div class="content">
  								<div class="inner">
  									<h2>Classifying strong lenses - Phillippa Hartley </h2>
  									<p>Formed when the light from a background galaxy is deflected by the mass of a foreground galaxy, 
										strong gravitational lenses are exotic cosmic objects, manifesting as dramatic arcs and rings in space. 
										Since the amount of deflection is independent of the type of matter, strong lenses can be used to investigate the distribution of dark matter, 
										allowing us to map and measure the dark Universe. Within the next decade several new sky surveys will yield hundreds of thousands of new lenses, 
										creating a statistically robust sample for the first time. Exploiting the scientific potential of these rare objects now depends on finding them within huge datasets. 
										Of high importance are the abilities of a finder both to outperform a human and to reject false positives due to intrinsic structure in galaxies. 
										I will present the support vector machine technique we have developed which does exactly this - https://arxiv.org/abs/1705.08949. 
										I will also present the results of the application of our finder to the Strong Gravitational Lens Challenge, 
										and to the search for lenses in real-life observations, where we have successfully found over a hundred new strong lens candidates - https://arxiv.org/abs/1802.03609. </p>
  									
									<td><a href="https://github.com/JBCA-MachineLearning/JBCA-MachineLearning.github.io/blob/master/journalclub_slides/PhillippaHartley_07072020_classifyingstronglenses.pdf" 
									       class="button primary small icon fa-download" target="_blank">Additional Slides</a></td>
									<td><a href="https://arxiv.org/abs/1705.08949" 
									       class="button primary small icon fa-download" target="_blank">Link to the SVM paper</a></td>
									<td><a href="https://arxiv.org/abs/1802.03609" 
									       class="button primary small icon fa-download" target="_blank">Link to the Gravitational Lens paper</a></td>
  								</div>
  							</div>
  						</section>
                        </section>
  						<section>			
							
				
	<!-- 2/6/2020 -->
  					<section id="3" class="wrapper style2 spotlights">
  						<section>
  							<a href="https://arxiv.org/pdf/1909.10963.pdf" class="image" target="_blank"><img src="images/umap-gqs.png" alt="" data-position="center center" /></a>
  							<div class="content">
  								<div class="inner">
  									<h2>Classifying galaxies, quasars and stars - Alex Clarke </h2>
  									<p> I will discuss my recent paper titled: Identifying galaxies, quasars, and stars with machine learning: A new catalogue of classifications for 111 million SDSS sources without spectra: 
										https://arxiv.org/abs/1909.10963. Here I focus on using a Random Forest to classify sources based on photometry, and also use dimension reduction with UMAP to visualise the classifications.
										Iâll also briefly discuss a paper that investigates obtaining photometric redshifts for sources found in radio surveys: Quasar photometric redshifts from SDSS, WISE and GALEX colours - https://arxiv.org/abs/2001.06514v1. 
										</p>
									<td><a href="https://docs.google.com/presentation/d/1r2D9P0JuQGMk2_RhQUQAsk3vunshTjhI22T_OnPPdt4/edit?usp=sharing" 
									       class="button primary small icon fa-download" target="_blank">Additional Slides</a></td>
									<td><a href="https://arxiv.org/pdf/1909.10963.pdf" 
									       class="button primary small icon fa-download" target="_blank">Link to the paper</a></td>
  									
  								</div>
  							</div>
  						</section>
                        </section>
  						<section>
				
				
          

               <!-- 5/5/2020 -->
  					<section id="2" class="wrapper style2 spotlights">
  						<section>
  							<a href="https://arxiv.org/abs/1909.00718v2" class="image" target="_blank"><img src="images/exoplanetatmosphere.png" alt="" data-position="center center" /></a>
  							<div class="content">
  								<div class="inner">
  									<h2>Optimizing exoplanet atmosphere retrieval - Josh Hayes </h2>
  									<p> Optimizing exoplanet atmosphere retrieval using unsupervised machine-learning classification. </p>
  									<td><a href="https://github.com/JBCA-MachineLearning/JBCA-MachineLearning.github.io/blob/master/journalclub_slides/JoshHayes_May2020.pdf" 
									       class="button primary small icon fa-download" target="_blank">Additional Slides</a></td>
									<td><a href="https://arxiv.org/abs/1909.00718v2" 
									       class="button primary small icon fa-download" target="_blank">Link to the paper</a></td>
  								</div>
  							</div>
  						</section>
                        </section>
  						<section>
			
							
							
		<!-- 7/4/2020 -->
  					<section id="1" class="wrapper style2 spotlights">
  						<section>
  							<a href="https://arxiv.org/pdf/2007.14849.pdf" class="image" target="_blank"><img src="images/colinclarkpulsar.png" alt="" data-position="center center" /></a>
  							<div class="content">
  								<div class="inner">
  									<h2>Timing Gamma-ray Pulsars using Gaussian Processes - Colin Clark </h2>
  									<p> Timing Gamma-ray Pulsars using Gaussian Processes. </p>
									<td><a href="https://arxiv.org/pdf/2007.14849.pdf" 
									       class="button primary small icon fa-download" target="_blank">Link to the paper</a></td>
  									
  								</div>
  							</div>
  						</section>
                        </section>
  						<section>
							
							

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper style1-alt">
				<div class="inner">
					<ul class="menu">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
